{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' Identify important content-level video features for each pipeline.\\nChallenge: 1. many features are highly correlated. how to reduce redundancy.\\n           2. identify \"all\" important features.\\n           \\nHigh-level description of our feature selection (two steps):\\n            1. Remove highly correlated features.\\n            2. Identify important features using different kinds of feature selection methods.\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''' Identify important content-level video features for each pipeline.\n",
    "Challenge: 1. many features are highly correlated. how to reduce redundancy.\n",
    "           2. identify \"all\" important features.\n",
    "           \n",
    "High-level description of our feature selection (two steps):\n",
    "            1. Remove highly correlated features.\n",
    "            2. Identify important features using different kinds of feature selection methods.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from collections import defaultdict\n",
    "import glob\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.svm import SVR\n",
    "from sklearn import preprocessing\n",
    "from sklearn.feature_selection import SelectFromModel, SelectKBest, mutual_info_regression\n",
    "from sklearn.ensemble import ExtraTreesClassifier, RandomForestRegressor\n",
    "from sklearn.linear_model import (LinearRegression, Ridge, \n",
    "\t\t\t\t\t\t\t\t  Lasso)\n",
    "from sklearn.feature_selection import RFE, f_regression\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from minepy import MINE\n",
    "import operator\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "sys.path.append('../')\n",
    "from pipeline_performance_loader import Parser, initialization, read_feature\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from VIF import ReduceVIF\n",
    "import seaborn as sns\n",
    "from scipy.stats import pearsonr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "driving2_3,0.0,0.0,0,0.0,0.0,0.0,-3.0,0.0,0.0,0.0,0.0,0.0,0.0,nan,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.017777777777777778,0,0.03079506172839507,0.17548521797688565,10.38655522428052,109.89372638584705,0.03079506172839507,0.0,0.0,0.0,0.0,0.0,2.252728336819822,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,-3.0,0.0,0.0,0.0,0.0,0.0,0.0,nan,0.0,0.0,0\n",
      "\n",
      "driving2_8,0.0,0.0,0,0.0,0.0,0.0,-3.0,0.0,0.0,0.0,0.0,0.0,0.0,nan,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0,0.0,0.0,0.0,-3.0,0.0,0.0,0.0,0.0,0.0,0.0,nan,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,-3.0,0.0,0.0,0.0,0.0,0.0,0.0,nan,0.0,0.0,0\n",
      "\n",
      "driving2_27,0.0,0.0,0,0.0,0.0,0.0,-3.0,0.0,0.0,0.0,0.0,0.0,0.0,nan,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0,0.0,0.0,0.0,-3.0,0.0,0.0,0.0,0.0,0.0,0.0,nan,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,-3.0,0.0,0.0,0.0,0.0,0.0,0.0,nan,0.0,0.0,0\n",
      "\n",
      "crossroad7_18,1.0,1.0,1,0.0,0.0,0.0,-3.0,0.0,1.0,1.0,1.0,1.0,0.0,6.802394763324314,0.072109375,0.07194850983796296,0.07267252604166667,2.729615783482095e-06,0.0016521548908870788,-1.1857641766666798,5.024720913803108,2.729615783482095e-06,0.070234375,0.07104275173611112,0.07292751736111111,0.07354817708333333,0.0018847656249999928,6.802128525381364,0.0,0.0,0,0.0,0.0,0.0,-3.0,0.0,0.0,0.0,0.0,0.0,0.0,nan,1.012218093273594,1.0191085241861841,1.0,0.0003076611029340436,0.017540270891124903,1.9255601262040638,4.531836257447585,0.0003076611029340436,1.0035829493087558,1.0077898095938829,1.0243618516967432,1.0445181283270557,0.01657204210286034,6.802248230691976,0.072109375,0.07194850983796296,0.07267252604166667,2.729615783482095e-06,0.0016521548908870788,-1.1857641766666798,5.024720913803108,2.729615783482095e-06,0.070234375,0.07104275173611112,0.07292751736111111,0.07354817708333333,0.0018847656249999928,6.802128525381364,1.0,0.0011111111111111111,1\n",
      "\n",
      "crossroad6_2,0.0,0.1622222222222222,0,0.13590617283950612,0.36865454403751236,1.8324894307740178,1.3580175138984805,0.13590617283950612,0.0,0.0,0.0,1.0,0.0,4.983606621708338,0.008813476562499999,0.009193563011320396,0.0032573784722222223,1.2408975781655793e-05,0.003522637617135176,0.518036005616243,-0.5953491970250844,1.2408975781655793e-05,0.005060763888888889,0.006407877604166666,0.011327039930555557,0.01489474826388889,0.004919162326388891,4.911074298627176,0.0,0.0,0,0.0,0.0,0.0,-3.0,0.0,0.0,0.0,0.0,0.0,0.0,nan,1.3277991324982144,1.3495040207880962,1.1092436974789917,0.013213697587146007,0.11495084857079571,1.482046377509159,5.97052063531342,0.013213697587146007,1.2144168798415056,1.2827003486673654,1.4095395818651633,1.4755032393713052,0.12683923319779788,4.980099082022633,0.0,0.0014914002218364198,0.0,1.350001891965856e-05,0.003674237188813286,2.450092533365193,5.037278722748349,1.350001891965856e-05,0.0,0.0,0.0,0.0077988281250000015,0.0,4.911074298627176,0.1622222222222222,0.0011111111111111111,1\n",
      "\n",
      "crossroad6_11,0.0,0.0,0,0.0,0.0,0.0,-3.0,0.0,0.0,0.0,0.0,0.0,0.0,nan,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0,0.0,0.0,0.0,-3.0,0.0,0.0,0.0,0.0,0.0,0.0,nan,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,-3.0,0.0,0.0,0.0,0.0,0.0,0.0,nan,0.0,0.0,0\n",
      "\n",
      "crossroad6_13,0.0,0.0,0,0.0,0.0,0.0,-3.0,0.0,0.0,0.0,0.0,0.0,0.0,nan,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0,0.0,0.0,0.0,-3.0,0.0,0.0,0.0,0.0,0.0,0.0,nan,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,-3.0,0.0,0.0,0.0,0.0,0.0,0.0,nan,0.0,0.0,0\n",
      "\n",
      "crossroad6_14,0.0,0.0,0,0.0,0.0,0.0,-3.0,0.0,0.0,0.0,0.0,0.0,0.0,nan,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0,0.0,0.0,0.0,-3.0,0.0,0.0,0.0,0.0,0.0,0.0,nan,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,-3.0,0.0,0.0,0.0,0.0,0.0,0.0,nan,0.0,0.0,0\n",
      "\n",
      "crossroad6_20,0.0,0.0,0,0.0,0.0,0.0,-3.0,0.0,0.0,0.0,0.0,0.0,0.0,nan,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0,0.0,0.0,0.0,-3.0,0.0,0.0,0.0,0.0,0.0,0.0,nan,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,-3.0,0.0,0.0,0.0,0.0,0.0,0.0,nan,0.0,0.0,0\n",
      "\n",
      "crossroad6_22,0.0,0.31555555555555553,0,0.21598024691358028,0.4647367501215933,0.7937588081690828,-1.3699469544539975,0.21598024691358028,0.0,0.0,1.0,1.0,1.0,5.648974238161207,0.0221875,0.056152148895980046,0.0193359375,0.0024630831673250245,0.04962945866443663,0.8170677995653032,-0.9433023572529904,0.0024630831673250245,0.013821506076388889,0.0188671875,0.0993967013888889,0.14016981336805556,0.0805295138888889,5.280901171562978,0.0,0.0,0,0.0,0.0,0.0,-3.0,0.0,0.0,0.0,0.0,0.0,0.0,nan,1.1508952794357026,1.1656497009154427,1.1747820254862509,0.006946573585755908,0.08334610720217177,0.7436877827871023,0.04507092719811645,0.006946573585755908,1.0697978979559704,1.1011955707835153,1.2218141222170864,1.2887019981366636,0.12061855143357114,5.628694658520913,0.0,0.01771912254050926,0.0,0.001458239080839994,0.03818689671654393,2.4286110069640716,4.725003277468641,0.001458239080839994,0.0,0.0,0.01784206814236111,0.0714296875,0.01784206814236111,5.280901171562977,0.31555555555555553,0.0011111111111111111,1\n",
      "\n",
      "crossroad6_23,0.0,0.0,0,0.0,0.0,0.0,-3.0,0.0,0.0,0.0,0.0,0.0,0.0,nan,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0,0.0,0.0,0.0,-3.0,0.0,0.0,0.0,0.0,0.0,0.0,nan,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,-3.0,0.0,0.0,0.0,0.0,0.0,0.0,nan,0.0,0.0,0\n",
      "\n",
      "crossroad6_25,0.0,0.0,0,0.0,0.0,0.0,-3.0,0.0,0.0,0.0,0.0,0.0,0.0,nan,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0,0.0,0.0,0.0,-3.0,0.0,0.0,0.0,0.0,0.0,0.0,nan,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,-3.0,0.0,0.0,0.0,0.0,0.0,0.0,nan,0.0,0.0,0\n",
      "\n",
      "crossroad6_26,0.0,0.0,0,0.0,0.0,0.0,-3.0,0.0,0.0,0.0,0.0,0.0,0.0,nan,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0,0.0,0.0,0.0,-3.0,0.0,0.0,0.0,0.0,0.0,0.0,nan,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,-3.0,0.0,0.0,0.0,0.0,0.0,0.0,nan,0.0,0.0,0\n",
      "\n",
      "crossroad6_27,0.0,0.0,0,0.0,0.0,0.0,-3.0,0.0,0.0,0.0,0.0,0.0,0.0,nan,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0,0.0,0.0,0.0,-3.0,0.0,0.0,0.0,0.0,0.0,0.0,nan,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,-3.0,0.0,0.0,0.0,0.0,0.0,0.0,nan,0.0,0.0,0\n",
      "\n",
      "crossroad6_36,0.0,0.0,0,0.0,0.0,0.0,-3.0,0.0,0.0,0.0,0.0,0.0,0.0,nan,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0,0.0,0.0,0.0,-3.0,0.0,0.0,0.0,0.0,0.0,0.0,nan,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,-3.0,0.0,0.0,0.0,0.0,0.0,0.0,nan,0.0,0.0,0\n",
      "\n",
      "cropped_driving2_3,0.0,0.0,0,0.0,0.0,0.0,-3.0,0.0,0.0,0.0,0.0,0.0,0.0,nan,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.011111111111111112,0,0.019876543209876547,0.14098419489388359,15.62318740715971,278.9015084294587,0.019876543209876547,0.0,0.0,0.0,0.0,0.0,1.8343719702816237,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,-3.0,0.0,0.0,0.0,0.0,0.0,0.0,nan,0.0,0.0,0\n",
      "\n",
      "cropped_driving2_5,0.0,0.0,0,0.0,0.0,0.0,-3.0,0.0,0.0,0.0,0.0,0.0,0.0,nan,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0,0.0,0.0,0.0,-3.0,0.0,0.0,0.0,0.0,0.0,0.0,nan,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,-3.0,0.0,0.0,0.0,0.0,0.0,0.0,nan,0.0,0.0,0\n",
      "\n",
      "cropped_driving2_6,0.0,0.0,0,0.0,0.0,0.0,-3.0,0.0,0.0,0.0,0.0,0.0,0.0,nan,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0,0.0,0.0,0.0,-3.0,0.0,0.0,0.0,0.0,0.0,0.0,nan,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,-3.0,0.0,0.0,0.0,0.0,0.0,0.0,nan,0.0,0.0,0\n",
      "\n",
      "cropped_crossroad4_3_1,1.0,1.0,1,0.0,0.0,0.0,-3.0,0.0,1.0,1.0,1.0,1.0,0.0,6.802394763324314,0.035416666666666666,0.035511217206790124,0.035833333333333335,4.381689758347295e-06,0.0020932486136021433,0.6311955150982022,2.3966506981514373,4.381689758347295e-06,0.03298611111111111,0.034166666666666665,0.03670247395833333,0.038311631944444445,0.002535807291666664,6.80067409636262,0.0,0.0,0,0.0,0.0,0.0,-3.0,0.0,0.0,0.0,0.0,0.0,0.0,nan,1.067663257277734,1.0750122340122568,1.0,0.0020605224961919143,0.0453929784899814,1.745226119020138,8.157285652783637,0.0020605224961919143,1.0229885057471264,1.044938219379189,1.098968064665739,1.1320129739690914,0.05402984528654997,6.801522602133676,0.035416666666666666,0.035511217206790124,0.035833333333333335,4.381689758347295e-06,0.0020932486136021433,0.6311955150982022,2.3966506981514373,4.381689758347295e-06,0.03298611111111111,0.034166666666666665,0.03670247395833333,0.038311631944444445,0.002535807291666664,6.80067409636262,1.0,0.0011111111111111111,1\n",
      "\n",
      "cropped_crossroad4_3_12,1.0,1.0,1,0.0,0.0,0.0,-3.0,0.0,1.0,1.0,1.0,1.0,0.0,6.802394763324314,0.023697916666666666,0.02384862075617284,0.023394097222222222,1.8199180018118723e-06,0.0013490433654304343,0.02877717983433442,-0.34459961753623913,1.8199180018118723e-06,0.022158854166666665,0.023020833333333334,0.024913194444444446,0.025577256944444446,0.001892361111111112,6.800793439531784,0.0,0.0,0,0.0,0.0,0.0,-3.0,0.0,0.0,0.0,0.0,0.0,0.0,nan,1.0420620373688094,1.051040282794889,1.0,0.0015445279743349783,0.03930048313106314,1.84008043246766,7.099015781659389,0.0015445279743349783,1.0121951219512195,1.025974025974026,1.069797138650959,1.0981966951382642,0.04382311267693306,6.80171023932572,0.023697916666666666,0.02384862075617284,0.023394097222222222,1.8199180018118723e-06,0.0013490433654304343,0.02877717983433442,-0.34459961753623913,1.8199180018118723e-06,0.022158854166666665,0.023020833333333334,0.024913194444444446,0.025577256944444446,0.001892361111111112,6.800793439531784,1.0,0.0011111111111111111,1\n",
      "\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../awstream/awstream_selected_video_resol_0.9_label_merge_add_width_20_filter.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-9943f8a555a3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mawstream_perf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mkeys\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'../awstream/awstream_selected_video_resol_0.9_label_merge_add_width_20_filter.csv'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m     \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../awstream/awstream_selected_video_resol_0.9_label_merge_add_width_20_filter.csv'"
     ]
    }
   ],
   "source": [
    "# Load pipeline performance\n",
    "all_feature_names, moving, video_to_delete, selected_video, glimpse_video_to_delete = initialization()\n",
    "path =  '../feature_analysis/video_features_30s/'\n",
    "# feature_file = path + 'features_all_type_width_height_filter.csv'\n",
    "feature_file = path + 'allvideo_features_long_add_width_20_filter.csv'\n",
    "features = read_feature(feature_file)\n",
    "video_to_delete = ['nyc', 'russia', 'tw', 'crossroad2','downtown','tw1','bridge','walking'\n",
    "]\n",
    "awstream_perf = {}\n",
    "keys = []\n",
    "with open('../awstream/awstream_selected_video_resol_0.9_label_merge_add_width_20_filter.csv', 'r') as f:\n",
    "    f.readline()\n",
    "    for line in f:\n",
    "        line_list = line.strip().split(',')\n",
    "        dataset_name = line_list[0].replace('_' + \n",
    "                       line_list[0].split('_')[-1], '')\n",
    "        if dataset_name in video_to_delete:\n",
    "            continue\n",
    "        key = line_list[0]\n",
    "        resol = int(line_list[2].replace('p', ''))\n",
    "        f1 = float(line_list[3])\n",
    "        bw = float(line_list[4])\n",
    "        awstream_perf[key] = (bw, f1, resol)\n",
    "        \n",
    "target_perf = awstream_perf\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/Users/zhujunxiao/Desktop/benchmarking/vldb/data/awstream/overfitting_results_30s_30s_label_merge/'\n",
    "awstream_profile = defaultdict(list)\n",
    "for file in glob.glob(path + 'awstream_spatial_overfitting_profile*.csv'):\n",
    "\twith open(file, 'r') as f:\n",
    "\t\tf.readline()\n",
    "\t\tfor line in f:\n",
    "\t\t\tline_list = line.strip().split(',')\n",
    "\t\t\tkey = line_list[0]\n",
    "\t\t\tresol = line_list[1]\n",
    "\t\t\tf1 = float(line_list[3])\n",
    "\t\t\tawstream_profile[key].append(f1)\n",
    "\n",
    "\n",
    "                \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = []\n",
    "y = []\n",
    "feature1 = []\n",
    "feature2 = []\n",
    "perf = []\n",
    "\n",
    "feature_perf_profile = {}\n",
    "for key in sorted(target_perf.keys()):\n",
    "    if key not in features:\n",
    "#         print('feature for {} not found'.format(key))\n",
    "        continue\n",
    "\n",
    "    # data cleaning\n",
    "    if features[key][all_feature_names.index('object_cn_avg')] <= 0:\n",
    "        continue\n",
    "    if features[key][all_feature_names.index('velocity_avg')] < 1:\n",
    "        continue\n",
    "    if features[key][all_feature_names.index('object_size_avg')] <= 0:\n",
    "        continue\n",
    "    thresh1 = 0.05\t\t\n",
    "#     if np.abs(target_perf[key][1] - 0.9) > thresh1:\n",
    "#         continue\n",
    "    if target_perf[key][1] < 0.9:\n",
    "        continue\n",
    "    X.append(features[key])\n",
    "    y.append(target_perf[key][0])        \n",
    "        \n",
    "    #************only for AWStream*******\n",
    "    \n",
    "#     if  total_object_cn[key] < 200:\n",
    "#         continue\n",
    "#     if features[key][all_feature_names.index('percentage')] > 0.8:\n",
    "#         continue\n",
    "#     if features[key][0] < 2:\n",
    "#         continue    \n",
    "    #************************************\n",
    "#     feature_perf_profile[key] = [target_perf[key], features[key], awstream_profile[key]]\n",
    "    \n",
    "# all_dataset = ['crossroad', 'crossroad2', 'crossroad3', 'crossroad4', 'drift',\n",
    "#                'driving1', 'driving2', 'highway', 'motorway', 'park', 'trip',\n",
    "#                'nyc', 'russia', 'russia1', 'tw', 'tw1','jp', 'downtown', \n",
    "#                'bridge', 'walking','hw', 'traffic', 'normal_traffic', 'split']\n",
    "# for dataset in all_dataset:\n",
    "#     feature_x = []\n",
    "#     perf_y = []\n",
    "#     for key in feature_perf_profile.keys():\n",
    "#         if dataset in key:\n",
    "#             feature_x.append(feature_perf_profile[key][1])\n",
    "#             perf_y.append(feature_perf_profile[key][0])\n",
    "    \n",
    "#     target_feature_index = all_feature_names.index('object_size_avg')\n",
    "#     plt.scatter([x[target_feature_index] for x in feature_x], [x[2] for x in perf_y])\n",
    "#     plt.title(dataset)\n",
    "#     plt.xlim(0, 0.04)\n",
    "#     plt.ylim(0,800)\n",
    "#     plt.show()\n",
    "    \n",
    "\n",
    "#     plt.annotate(key, (features[key][all_feature_names.index('object_size_avg')], awstream_profile[key][1]))\n",
    "\n",
    "\n",
    "# plt.xscale('logit')\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(X, columns=all_feature_names)\n",
    "\n",
    "plt.scatter(df['object_size_percentile10'], y)\n",
    "plt.ylim(0,1)\n",
    "plt.xlim(0.001,0.025)\n",
    "plt.xscale('logit')\n",
    "plt.show()\n",
    "# for name in all_feature_names:\n",
    "#     (r, p) = pearsonr(df[name], y)\n",
    "#     if abs(r) > 0.3:\n",
    "#         print(name, r, p)\n",
    "#         plt.scatter(df[name], y)\n",
    "#         plt.title(name)\n",
    "        \n",
    "#         plt.show()\n",
    "\n",
    "\n",
    "# new_df = df[['percentage','percentage_w_new_object', 'velocity_avg', 'velocity_var', 'arrival_rate_avg', 'arrival_rate_var','object_cn_avg', 'object_cn_var',\n",
    "#             'object_size_avg','object_size_var', 'total_area_avg','total_area_var']]\n",
    "\n",
    "# hist = new_df.hist(bins=10, figsize=(12, 12))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create our function which stores the feature rankings to the ranks dictionary\n",
    "def ranking(ranks, names, order=1):\n",
    "    minmax = MinMaxScaler()\n",
    "    ranks = minmax.fit_transform(order*np.array([ranks]).T).T[0]\n",
    "    ranks = map(lambda x: round(x,2), ranks)\n",
    "    return dict(zip(names, ranks))\n",
    "\n",
    "\n",
    "def rank_to_dict(ranks, names, order=1):\n",
    "#     minmax = MinMaxScaler()\n",
    "#     ranks = minmax.fit_transform(order*np.array([ranks]).T).T[0]\n",
    "    ranks = map(lambda x: round(x, 2), ranks)\n",
    "    return dict(zip(names, ranks ))\n",
    "\n",
    "def topK_index(data, K):\n",
    "    indices = data.argsort()[-1*K:][::-1]\n",
    "    return indices, data[indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_filtering(df, filter_method='pearson'):\n",
    "\t# remove correlated features\n",
    "\tif filter_method == 'VIF':\n",
    "\t\t# filter \n",
    "\t\ttransformer = ReduceVIF(thresh=5)\n",
    "\t\tdf_filtered = transformer.fit_transform(df)\n",
    "\t\treturn df_filtered\n",
    "\telif filter_method == 'pearson':\n",
    "\t\t# filter feateures with pearson correlation higher than a thresh\n",
    "\t\tcorr_matrix = df.corr()\n",
    "\t\tcorrelated_features = set()\n",
    "\t\tthresh = 0.8\n",
    "\t\tfor i in range(len(corr_matrix.columns)):\n",
    "\t\t\tfor j in range(i):\n",
    "\t\t\t\tif abs(corr_matrix.iloc[i, j]) > thresh:\n",
    "\t\t\t\t\tcolname = corr_matrix.columns[i]\n",
    "\t\t\t\t\tcorrelated_features.add(colname)\n",
    "\t\tdf_filtered = df.drop(correlated_features, axis=1)\n",
    "\t\treturn df_filtered\n",
    "\n",
    "\t\n",
    "\telse:\n",
    "\t\tprint('Filter method {} does not exist.'.format(filter_method))\n",
    "\t\treturn df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocessing: standardization, and train test split\n",
    "print('Preprocessing starts (normalization, train_test_split)......')\n",
    "scaler = preprocessing.StandardScaler().fit(X)\n",
    "X_scaled = scaler.transform(X)  \n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, \n",
    "                                    test_size=0.2, random_state=0)\n",
    "\n",
    "# remove correlated features, using two methods\n",
    "df = pd.DataFrame(X_train, columns=all_feature_names)\n",
    "df_filtered_pearson = feature_filtering(df)\n",
    "print('After pearson correlation filtering, remaining features:', df_filtered_pearson.columns)\n",
    "df_filtered_vif = feature_filtering(df, filter_method='VIF')\n",
    "print('After VIF filtering, remaining features:', df_filtered_vif.columns)\n",
    "\n",
    "# visualize correlation matrix before and after filtering\n",
    "df['perf'] = y_train\n",
    "df_filtered_pearson['perf'] = y_train\n",
    "df_filtered_vif['perf'] = y_train\n",
    "\n",
    "# f,(ax1,ax2,ax3) = plt.subplots(1,3,sharey=True)\n",
    "cor = df.corr()\n",
    "sns.heatmap(cor, vmin=-1, vmax=1, center=0)\n",
    "plt.title('Correlation matrix before feature filtering.')\n",
    "plt.show()\n",
    "cor = df_filtered_vif.corr()\n",
    "sns.heatmap(cor, vmin=-1, vmax=1, center=0)\n",
    "plt.title('Correlation matrix after VIF filtering.')\n",
    "plt.show()\n",
    "cor = df_filtered_pearson.corr()\n",
    "sns.heatmap(cor, vmin=-1, vmax=1, center=0)\n",
    "plt.title('Correlation matrix before feature filtering.')\n",
    "plt.show()\t\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implement multiple types of feature selection methods. And compare their selected results.\n",
    "\n",
    "def select_good_features(X, Y, names, n_features_to_select=5):\n",
    "    ranks = {}\n",
    "    lr = LinearRegression(normalize=True)\n",
    "    lr.fit(X, Y)\n",
    "    ranks[\"Linear\"] = rank_to_dict(np.abs(lr.coef_), names)\n",
    "\n",
    "    ridge = Ridge(alpha=7)\n",
    "    ridge.fit(X, Y)\n",
    "    ranks[\"Ridge\"] = rank_to_dict(np.abs(ridge.coef_), names)\n",
    "\n",
    "\n",
    "    lasso = Lasso(alpha=.05)\n",
    "    lasso.fit(X, Y)\n",
    "    ranks[\"Lasso\"] = rank_to_dict(np.abs(lasso.coef_), names)\n",
    "\n",
    "\n",
    "    #stop the search when 5 features are left (they will get equal scores)\n",
    "    rfe = RFE(lr, n_features_to_select=5)\n",
    "    rfe.fit(X,Y)\n",
    "    ranks[\"RFE\"] = rank_to_dict(rfe.ranking_, names, order=-1)\n",
    "\n",
    "    rf = RandomForestRegressor()\n",
    "    rf.fit(X,Y)\n",
    "    ranks[\"RF\"] = rank_to_dict(rf.feature_importances_, names)\n",
    "\n",
    "\n",
    "    f, pval  = f_regression(X, Y, center=True)\n",
    "    ranks[\"Corr.\"] = rank_to_dict(f, names)\n",
    "\n",
    "    mine = MINE()\n",
    "    mic_scores = []\n",
    "    for i in range(X.shape[1]):\n",
    "        mine.compute_score(X[:,i], Y)\n",
    "        m = mine.mic()\n",
    "        mic_scores.append(m)\n",
    "\n",
    "    ranks[\"MIC\"] = rank_to_dict(mic_scores, names) \n",
    "    r = {}\n",
    "    for name in names:\n",
    "        r[name] = round(np.mean([ranks[method][name] \n",
    "                                 for method in ranks.keys()]), 2)\n",
    "\n",
    "    methods = sorted(ranks.keys())\n",
    "    ranks[\"Mean\"] = r\n",
    "    methods.append(\"Mean\")\n",
    "\n",
    "  \n",
    "\n",
    "    # rank = [np.abs(x) for x in lr.feature_importances_]\n",
    "    # indicies = topK_index(np.asarray(rank), 3)\n",
    "\n",
    "    # for i in indicies[0]:\n",
    "    # \tprint(all_feature_names[i])\n",
    "\n",
    "    return methods, ranks\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = df.drop(['perf'], axis=1)\n",
    "X = features.as_matrix()\n",
    "Y = df['perf']\n",
    "names = features.columns.values\n",
    "print('The shape of feature matrix:', X.shape)\n",
    "print('all feature names:', names)\n",
    "methods, ranks = select_good_features(X, Y, names, n_features_to_select=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"%30s\\t%s\" % ('Feature name', \"\\t\".join(methods)))\n",
    "for name in names:\n",
    "    print(\"%30s\\t%s\" % (name, \"\\t\".join(map(str, \n",
    "                         [ranks[method][name] for method in methods])))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for method in methods:\n",
    "    new_rank = {k: v for k, v in sorted(ranks[method].items(), key=lambda item: item[1], reverse=True)}\n",
    "    rank_iterator = iter(new_rank)\n",
    "    print('Selected features of method {}:'.format(method))\n",
    "    for i in range(3):\n",
    "        selected_feature = next(rank_iterator)\n",
    "        feature_importance = new_rank[selected_feature]\n",
    "        print(selected_feature, feature_importance)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = df_filtered_pearson.drop(['perf'], axis=1)\n",
    "X = features.as_matrix()\n",
    "Y = df_filtered_pearson['perf']\n",
    "names = features.columns.values\n",
    "print('The shape of feature matrix:', X.shape)\n",
    "print('all feature names:', names)\n",
    "methods, ranks = select_good_features(X, Y, names, n_features_to_select=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"%30s\\t%s\" % ('Feature name', \"\\t\".join(methods)))\n",
    "for name in names:\n",
    "    print(\"%30s\\t%s\" % (name, \"\\t\".join(map(str, \n",
    "                         [ranks[method][name] for method in methods])))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for method in methods:\n",
    "    new_rank = {k: v for k, v in sorted(ranks[method].items(), key=lambda item: item[1], reverse=True)}\n",
    "    rank_iterator = iter(new_rank)\n",
    "    print('Selected features of method {}:'.format(method))\n",
    "    for i in range(3):\n",
    "        selected_feature = next(rank_iterator)\n",
    "        feature_importance = new_rank[selected_feature]\n",
    "        print(selected_feature, feature_importance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = df_filtered_vif.drop(['perf'], axis=1)\n",
    "X = features.as_matrix()\n",
    "Y = df_filtered_vif['perf']\n",
    "names = features.columns.values\n",
    "print('The shape of feature matrix:', X.shape)\n",
    "print('all feature names:', names)\n",
    "methods, ranks = select_good_features(X, Y, names, n_features_to_select=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"%30s\\t%s\" % ('Feature name', \"\\t\".join(methods)))\n",
    "for name in names:\n",
    "    print(\"%30s\\t%s\" % (name, \"\\t\".join(map(str, \n",
    "                         [ranks[method][name] for method in methods])))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for method in methods:\n",
    "    new_rank = {k: v for k, v in sorted(ranks[method].items(), key=lambda item: item[1], reverse=True)}\n",
    "    rank_iterator = iter(new_rank)\n",
    "    print('Selected features of method {}:'.format(method))\n",
    "    for i in range(3):\n",
    "        selected_feature = next(rank_iterator)\n",
    "        feature_importance = new_rank[selected_feature]\n",
    "        print(selected_feature, feature_importance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import pearsonr\n",
    "\n",
    "features = df.drop(['perf'], axis=1)\n",
    "X = features.as_matrix()\n",
    "Y = df['perf']\n",
    "names = features.columns.values\n",
    "correlation_thresh = 0.3\n",
    "correlated_features = []\n",
    "for name in names:\n",
    "    (r, p) = pearsonr(df[name], df['perf'])\n",
    "    if np.abs(r) > correlation_thresh:\n",
    "        correlated_features.append((name,r))\n",
    "correlated_features.sort(key=lambda x: x[1], reverse=True)\n",
    "print(correlated_features)\n",
    "selected_features = [correlated_features[0][0]]\n",
    "for feature in correlated_features[1:]:\n",
    "    (r, p) = pearsonr(df[feature[0]], df[correlated_features[0][0]])\n",
    "    if np.abs(r) <= 0.8:\n",
    "        selected_features.append(feature[0])\n",
    "print('Final selected feature:', selected_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "newenv",
   "language": "python",
   "name": "newenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
